{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jules-4LL4RT/Internship/blob/main/Test_SVM_and_RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3G675XQUaRuC",
        "outputId": "79b0d659-797d-434c-82f3-83ea493915ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.5810659   0.42196824 -0.80497402 -0.50860702]\n",
            " [-1.52079513 -1.67737625 -1.08231219 -0.86427627]\n",
            " [-0.89430898 -1.4674418   0.30437864  0.38056609]\n",
            " [-0.5810659  -1.25750735  0.09637501  0.55840072]]\n",
            "[23 41 57 98]\n",
            "[2 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4107    0]\n",
            " [   0 3093]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      4107\n",
            "           1       1.00      1.00      1.00      3093\n",
            "\n",
            "    accuracy                           1.00      7200\n",
            "   macro avg       1.00      1.00      1.00      7200\n",
            "weighted avg       1.00      1.00      1.00      7200\n",
            "\n",
            "[[3259  848]\n",
            " [ 790 2303]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.79      0.80      4107\n",
            "           1       0.73      0.74      0.74      3093\n",
            "\n",
            "    accuracy                           0.77      7200\n",
            "   macro avg       0.77      0.77      0.77      7200\n",
            "weighted avg       0.77      0.77      0.77      7200\n",
            "\n",
            "(1000, 20) (1000,)\n",
            "Accuracy: 0.907 (0.025)\n",
            "Predicted Class: 0\n",
            "MAE = -60.68 (6.81)\n",
            "Prediction: -166\n",
            ">0.0 0.793 (0.067)\n",
            ">0.1 0.861 (0.059)\n",
            ">0.2 0.877 (0.058)\n",
            ">0.3 0.887 (0.058)\n",
            ">0.4 0.897 (0.055)\n",
            ">0.5 0.898 (0.057)\n",
            ">0.6 0.897 (0.053)\n",
            ">0.7 0.903 (0.055)\n",
            ">0.8 0.901 (0.052)\n",
            ">0.9 0.908 (0.052)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "150 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "150 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
            "    n_samples=X.shape[0], max_samples=self.max_samples\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 117, in _get_n_samples_bootstrap\n",
            "    raise ValueError(msg.format(max_samples))\n",
            "ValueError: `max_samples` must be in range (0.0, 1.0] but got value 1.01\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">1.0 nan (nan)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "150 fits failed out of a total of 150.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "150 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 386, in fit\n",
            "    n_samples=X.shape[0], max_samples=self.max_samples\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 117, in _get_n_samples_bootstrap\n",
            "    raise ValueError(msg.format(max_samples))\n",
            "ValueError: `max_samples` must be in range (0.0, 1.0] but got value 1.06\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">1.1 nan (nan)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "409.5027449131012\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow.keras.utils import get_file\n",
        "from time import time\n",
        "from sklearn.datasets import make_classification\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn import metrics\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from numpy import arange\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Load data with only two classes\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:100,:]\n",
        "y = iris.target[:100]\n",
        "\n",
        "# Standarize features\n",
        "scaler = StandardScaler()\n",
        "X_std = scaler.fit_transform(X)\n",
        "\n",
        "# Create support vector classifier object\n",
        "svc = SVC(kernel='linear', random_state=2)\n",
        "\n",
        "# Train classifier\n",
        "model = svc.fit(X_std, y)\n",
        "\n",
        "# View support vectors\n",
        "print(model.support_vectors_)\n",
        "\n",
        "\n",
        "# View indices of support vectors\n",
        "print(model.support_)\n",
        "\n",
        "# View number of support vectors for each class\n",
        "print(model.n_support_)\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/Jules-4LL4RT/Internship/main/iris.data\"\n",
        "\n",
        "t0 = time()\n",
        "\n",
        "try:\n",
        "    path = get_file('newFridayAfternoonDDoSaa.csv', origin=\\\n",
        "\t\t'https://raw.githubusercontent.com/Jules-4LL4RT/Internship/main/newFridayAfternoonDDoSaa.csv',archive_format=None)\n",
        "except:\n",
        "   print('Something went wrong, please try again')\n",
        "   raise\n",
        "\n",
        "# Assign column names to the dataset\n",
        "colnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
        "\n",
        "colnames2 =  ['Flow ID', ' Source IP', ' Source Port', ' Destination IP', ' Destination Port', ' Protocol', ' Timestamp',\n",
        "              ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets', ' Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
        "\t\t\t\t\t\t  ' Fwd Packet Length Max', ' Fwd Packet Length Min', ' Fwd Packet Length Mean', ' Fwd Packet Length Std', ' Bwd Packet Length Max',\n",
        "\t\t\t\t\t\t  ' Bwd Packet Length Min', ' Bwd Packet Length Mean', ' Bwd Packet Length Std', ' Flow Bytes/s',\n",
        "              ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Fwd IAT Max', ' Flow IAT Min', ' Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
        "\t\t\t\t\t\t  ' Fwd IAT Max', ' Flow IAT Min', ' Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std', ' Fwd IAT Max', ' Fwd IAT Min', ' Bwd IAT Total', ' Bwd IAT Mean', \n",
        "\t\t\t\t\t\t  ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', ' Fwd PSH Flags', ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags', ' Fwd Header Length',\n",
        "\t\t\t\t\t\t  ' Bwd Header Length', ' Fwd Packets/s', ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
        "\t\t\t\t\t\t\t' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance', ' FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
        "\t\t\t\t\t\t\t' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count', ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio', ' Average Packet Size',\n",
        "\t\t\t\t\t\t\t' Avg Fwd Segment Size', ' Avg Bwd Segment Size', ' Fwd Header Length', ' Fwd Avg Bytes/Bulk', ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate',\n",
        "\t\t\t\t\t\t\t' Bwd Avg Bulk Rate',' Subflow Fwd Packets', ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes', ' Init_Win_bytes_forward',\n",
        "\t\t\t\t\t\t\t' Init_Win_bytes_backward', ' act_data_pkt_fwd',' min_seg_size_forward', ' Active Mean', ' Active Std', ' Active Max', ' Active Min',\n",
        "\t\t\t\t\t\t\t' Idle Mean', ' Idle Std', ' Idle Max', ' Idle Min', ' Label']\n",
        "\t\t\t\t\t\t  \n",
        "# Read dataset to pandas dataframe\n",
        "#irisdata = pd.read_csv(url, names=colnames)\n",
        "\n",
        "df = pd.read_csv(path, sep=',',error_bad_lines=True)\n",
        "\n",
        "#Sample X% of the dataset\n",
        "#Replace=false because same row can't be sampled 2 times\n",
        "df = df.sample(frac=0.80, replace=False)\n",
        "\n",
        "#X = irisdata.drop('Class', axis=1)\n",
        "#y = irisdata['Class']\n",
        "df = df.drop(columns=[' Fwd Header Length'])\n",
        "\n",
        "df[' Label'].unique()\n",
        "\n",
        "df[' Label'].value_counts()\n",
        "\n",
        "df = df.drop(df[pd.isnull(df['Flow ID'])].index)\n",
        "\n",
        "df[' Label'] = df[' Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
        "#Replace \"infinity\" values by -1\n",
        "df.replace('Infinity', -1, inplace=True)\n",
        "#Consider values in these columns as numerical values\n",
        "df[['Flow Bytes/s', ' Flow Packets/s']] = df[['Flow Bytes/s', ' Flow Packets/s']].apply(pd.to_numeric)\n",
        "\n",
        "#Replace infinity and anassigned values by -1\n",
        "df.replace([np.inf, -np.inf, np.nan], -1, inplace=True)\n",
        "\n",
        "excluded = ['Flow ID', ' Source IP', ' Source Port', ' Destination IP', ' Destination Port', ' Protocol', ' Timestamp']\n",
        "df = df.drop(columns=excluded, errors='ignore')\n",
        "\n",
        "y = df[' Label']\n",
        "X = df.drop(columns=[' Label'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=40)\n",
        "'''\n",
        "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
        "    if mean is None:\n",
        "        mean = df[name].mean()\n",
        "\n",
        "    if sd is None:\n",
        "        sd = df[name].std()\n",
        "\n",
        "    df[name] = (df[name] - mean) / sd\n",
        "\n",
        "#Dummy variables (ex: temp can be hot, medium or cold)\n",
        "#Axis=1 means columns\n",
        "def encode_text_dummy(df, name):\n",
        "    dummies = pd.get_dummies(df[name])\n",
        "    for x in dummies.columns:\n",
        "        dummy_name = f\"{name}-{x}\"\n",
        "        df[dummy_name] = dummies[x]\n",
        "    df.drop(name, axis=1, inplace=True)\n",
        "\n",
        "#Encoding depends of data types\n",
        "for name in df.columns:\n",
        "  if name == ' Label':\n",
        "    pass\n",
        "  elif name in [' Source IP',' Destination IP', 'Flow ID',' Timestamp']:\n",
        "    encode_text_dummy(df,name)\n",
        "  #elif name in [' Source IP',' Destination IP']:\n",
        "    #name = ipaddress.ip_address(name)\n",
        "    #encode_numeric_zscore(df,name)\n",
        "  #elif name in ['Flow ID',' Timestamp']:\n",
        "    #encode_text_dummy(df,name)\n",
        "  else:\n",
        "    encode_numeric_zscore(df,name)\n",
        "'''\n",
        "#svclassifier = SVC(kernel='poly', degree=8)\n",
        "#svclassifier.fit(X_train, y_train)\n",
        "#y_pred = svclassifier.predict(X_test)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=250, random_state=42, oob_score=True)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "svclassifier = SVC(kernel='rbf')\n",
        "svclassifier.fit(X_train, y_train)\n",
        "svclassifier = SVC(kernel='sigmoid')\n",
        "svclassifier.fit(X_train, y_train)\n",
        "y_pred = svclassifier.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "# define the model\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# evaluate the model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\n",
        "# reportaccuracy\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "\n",
        "# define the model\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# fit the model on the whole dataset\n",
        "model.fit(X, y)\n",
        "\n",
        "# make a single prediction\n",
        "row = [[-2.8239,5.3884,8.2983,-1.02741,-0.1251,4.3802,0.1937,-1.6421,-6.5183,\n",
        "        -3.1083,1.6113,1.3920,6.8440,0.4291,-3.2901,-1.2034,0.6882,1.135,2.286,-0.1835]]\n",
        "yhat = model.predict(row)\n",
        "print('Predicted Class: %d' % yhat[0])\n",
        "\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=500, n_features=20, n_informative=15, noise=0.1, random_state=2)\n",
        "\n",
        "# define the model\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# evaluate the model\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
        "\n",
        "# report performance\n",
        "print('MAE = %.2f (%.2f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "# random forest for making predictions for regression\n",
        "\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=2)\n",
        "\n",
        "# define the model\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# fit the model on the whole dataset\n",
        "model.fit(X, y)\n",
        "\n",
        "# make a single prediction\n",
        "row = [[-0.89483109,-1.0670149,-0.25448694,-0.53850126,0.21082105,1.37435592,0.71203659,0.73093031,-1.25878104,-2.01656886,0.51906798,0.62767387,0.96250155,1.31410617,-1.25527295,-0.85079036,0.24129757,-0.17571721,-1.11454339,0.36268268]]\n",
        "yhat = model.predict(row)\n",
        "\n",
        "print('Prediction: %d' % yhat[0])\n",
        "\n",
        "\n",
        "\n",
        "# explore random forest bootstrap sample size on performance\n",
        "#Mean accuracy depending of dataset size\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "\treturn X, y\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\t# explore ratios from 10% to 100% in 10% increments\n",
        "\tfor i in arange(0.1, 1.1, 0.1):\n",
        "\t\tkey = '%.1f' % i\n",
        "\t\t# set max_samples=None to use 100%\n",
        "\t\tif i == 1.0:\n",
        "\t\t\ti = None\n",
        "\t\tmodels[key] = RandomForestClassifier(max_samples=i)\n",
        "\treturn models\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\t# define the evaluation procedure\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=30, n_repeats=5, random_state=1)\n",
        "\t# evaluate the model and collect the results\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\t# evaluate the model\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\t# store the results\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\t# summarize the performance along the way\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()\n",
        "'''\n",
        "# explore random forest number of features effect on performance\n",
        "# Mean accuracy depending of feature set size\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\t# explore number of features from 1 to 8\n",
        "\tfor i in range(1,8):\n",
        "\t\tmodels[str(i)] = RandomForestClassifier(max_features=i)\n",
        "\treturn models\n",
        "\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\t# define the evaluation procedure\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=13)\n",
        "\t# evaluate the model and collect the results\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\t# evaluate the model\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\t# store the result\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\t# summarize the performance along the way\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        " \n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()\n",
        "\n",
        "# explore random forest number of trees effect on performance\n",
        "#Mean accuracy depending of number of trees\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=500, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\t# define number of trees to consider\n",
        "\tn_trees = [10, 50, 100, 500, 1000]\n",
        "\tfor n in n_trees:\n",
        "\t\tmodels[str(n)] = RandomForestClassifier(n_estimators=n)\n",
        "\treturn models\n",
        "\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\t# define the evaluation procedure\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\t# evaluate the model and collect the results\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        "\n",
        "# define dataset\n",
        "X, y = get_dataset()\n",
        "\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\t# evaluate the model\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\t# store the results\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\t# summarize the performance along the way\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show() \n",
        "\n",
        "# explore random forest tree depth effect on performance\n",
        "#Maximum depth of decision trees\n",
        "\n",
        "# get the dataset\n",
        "def get_dataset():\n",
        "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=3)\n",
        "\treturn X, y\n",
        "\n",
        "# get a list of models to evaluate\n",
        "def get_models():\n",
        "\tmodels = dict()\n",
        "\t# consider tree depths from 1 to 7 and None=full\n",
        "\tdepths = [i for i in range(1,7)] + [None]\n",
        "\tfor n in depths:\n",
        "\t\tmodels[str(n)] = RandomForestClassifier(max_depth=n)\n",
        "\treturn models\n",
        "\n",
        "# evaluate a given model using cross-validation\n",
        "def evaluate_model(model, X, y):\n",
        "\t# define the evaluation procedure\n",
        "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\t# evaluate the model and collect the results\n",
        "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\treturn scores\n",
        "\n",
        "# define the dataset\n",
        "X, y = get_dataset()\n",
        "\n",
        "# get the models to evaluate\n",
        "models = get_models()\n",
        "\n",
        "# evaluate the models and store results\n",
        "results, names = list(), list()\n",
        "for name, model in models.items():\n",
        "\t#evaluate the model\n",
        "\tscores = evaluate_model(model, X, y)\n",
        "\t# store the results\n",
        "\tresults.append(scores)\n",
        "\tnames.append(name)\n",
        "\t# summarize the performance along the way\n",
        "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
        "\n",
        "# plot model performance for comparison\n",
        "pyplot.boxplot(results, labels=names, showmeans=True)\n",
        "pyplot.show()\n",
        "'''\n",
        "print(time() - t0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Lk25y5MK-qnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Test_SVM_and_RF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO+3N8FW0yOwFpLU6e5VLGX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}